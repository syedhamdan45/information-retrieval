{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Information Retrieval Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdkwQ36739Wi",
        "colab_type": "text"
      },
      "source": [
        "# Information Retrieval Project\n",
        "\n",
        "Three important softwares used:\n",
        "- Whoosh, a pure-Python search engineering library, \n",
        "- NLTK, a natural language processing toolkit and \n",
        "- pytrec eval, an Information Retrieval evaluation tool for Python, based  on the popular trec eval, the standard software for evaluating search engines with test collections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-gYMXKq39Wj",
        "colab_type": "text"
      },
      "source": [
        "## Preparations\n",
        "* Put all your imports, and path constants in the next cells\n",
        "* Make sure all your path constants are **relative to** ***DATA_DIR*** and **NOT hard-coded** in your code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSChF98s8ErB",
        "colab_type": "code",
        "outputId": "b2439469-21ca-4e9e-a84e-e0fa7ffe9e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!pip install whoosh\n",
        "!pip install pytrec_eval\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting whoosh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
            "\r\u001b[K     |▊                               | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 6.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 471kB 8.3MB/s \n",
            "\u001b[?25hInstalling collected packages: whoosh\n",
            "Successfully installed whoosh-2.7.4\n",
            "Collecting pytrec_eval\n",
            "  Downloading https://files.pythonhosted.org/packages/36/0a/5809ba805e62c98f81e19d6007132712945c78e7612c11f61bac76a25ba3/pytrec_eval-0.4.tar.gz\n",
            "Building wheels for collected packages: pytrec-eval\n",
            "  Building wheel for pytrec-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec-eval: filename=pytrec_eval-0.4-cp36-cp36m-linux_x86_64.whl size=273434 sha256=46245cffaa56c47badc6f7828e0df9575f66014fb2ebe80b2ab53592711170bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/30/73/8858a1b6e5e2674e2ea85c9904949c06addcf6fd34d59b5ea6\n",
            "Successfully built pytrec-eval\n",
            "Installing collected packages: pytrec-eval\n",
            "Successfully installed pytrec-eval-0.4\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=033f06596db5e16a575abf5aac5a99a2ad32d2e782de90dbaf8c2099cd2d38ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HIF5uBV8cRy",
        "colab_type": "code",
        "outputId": "5f91afc4-9fce-4fa3-9b2f-363b1446b6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/government.zip\", \"government.zip\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'government (1).zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN-TAsbPAsRm",
        "colab_type": "code",
        "outputId": "e187228e-aea5-4e25-ab06-d7d6dff6bb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip government.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  government.zip\n",
            "replace government/topics-with-full-descriptions.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VNv24P839Wk",
        "colab_type": "code",
        "outputId": "bf03a765-88df-4e13-8927-dfccaca60d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# imports\n",
        "from whoosh import index, writing, scoring, qparser\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.analysis import *\n",
        "from whoosh.qparser import QueryParser, OrGroup, AndGroup\n",
        "from whoosh.scoring import BM25F, TF_IDF, Frequency\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import subprocess\n",
        "import pytrec_eval\n",
        "import wget\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.stem import *\n",
        "# download required resources\n",
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CTt1NZr39Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = \"government\"\n",
        "#\n",
        "# Put other path constants here\n",
        "#\n",
        "DOCUMENTS_DIR = os.path.join(DATA_DIR, \"documents\")\n",
        "TOPIC_FILE = os.path.join(DATA_DIR, \"gov.topics\")\n",
        "QRELS_FILE = os.path.join(DATA_DIR, \"gov.qrels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaUGqA-cLx9o",
        "colab_type": "text"
      },
      "source": [
        "## Final Summary:\n",
        "\n",
        "- The most useful trec_eval measures is MAP (Mean Average Precision). MAP considers ranking of each relevant document (unlike P@K) and empirically correlates with human evaluation of retrieval systems\n",
        "- The MAP for the baseline whoosh is 0.1971\n",
        "- MAP was increased to 0.3372 by just using Lower case and Stem Filter\n",
        "- Final MAP is 0.4098 after a series of modifications made including trying out more filters, stemmers/lemmatizers, scoring methods, query parser customizations and parameter tuning for BM25F and PL2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZmmZ72GIkI6",
        "colab_type": "text"
      },
      "source": [
        "## Indexing and Querying"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZkoByd39Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating Index\n",
        "def createIndex(schema):\n",
        "    # Generate a temporary directory for the index\n",
        "    indexDir = tempfile.mkdtemp()\n",
        "\n",
        "    # create and return the index\n",
        "    return index.create_in(indexDir, schema)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC5HHjgHq2Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first, define a Schema for the index\n",
        "mySchema = Schema(file_path = ID(stored=True),\n",
        "                  file_content = TEXT(analyzer = RegexTokenizer()))\n",
        "\n",
        "# now, create the index at the path INDEX_DIR based on the new schema\n",
        "myIndex = createIndex(mySchema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHwotpJ4rAni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addFilesToIndex(indexObj, fileList):\n",
        "    # open writer\n",
        "    writer = writing.BufferedWriter(indexObj, period=None, limit=1000)\n",
        "\n",
        "    try:\n",
        "        # write each file to index\n",
        "        for docNum, filePath in enumerate(fileList):\n",
        "            with open(filePath, \"r\", encoding=\"utf-8\") as f:\n",
        "                fileContent = f.read()\n",
        "                writer.add_document(file_path = filePath,\n",
        "                                    file_content = fileContent)\n",
        "\n",
        "                # print status every 1000 documents\n",
        "                if (docNum+1) % 1000 == 0:\n",
        "                    print(\"already indexed:\", docNum+1)\n",
        "        print(\"done indexing.\")\n",
        "\n",
        "    finally:\n",
        "        # close the index\n",
        "        writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87e3Gf3ruhVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a list of files to index\n",
        "filesToIndex = [str(filePath) for filePath in Path(DOCUMENTS_DIR).glob(\"**/*\") if filePath.is_file()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxYY2AWDv12P",
        "colab_type": "code",
        "outputId": "c8295e6d-1d90-4d47-fada-a6f8c14a0531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "addFilesToIndex(myIndex, filesToIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already indexed: 1000\n",
            "already indexed: 2000\n",
            "already indexed: 3000\n",
            "already indexed: 4000\n",
            "done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibPPoKXF39Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Q2 = myIndex # Replace None with your index for Q2\n",
        "QP_Q2 = QueryParser(\"file_content\", schema=INDEX_Q2.schema) # Replace None with your query parser for Q2\n",
        "SEARCHER_Q2 = INDEX_Q2.searcher() # Replace None with your searcher for Q2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tJCx_AKwwvn",
        "colab_type": "code",
        "outputId": "a88c32eb-e6e5-4172-e37e-2f9395a6df5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# print the topic file\n",
        "with open(TOPIC_FILE, \"r\") as f:\n",
        "    print(f.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 mining gold silver coal\n",
            "2 juvenile delinquency\n",
            "4 wireless communications\n",
            "6 physical therapists\n",
            "7 cotton industry\n",
            "9 genealogy searches\n",
            "10 Physical Fitness\n",
            "14 Agricultural biotechnology\n",
            "16 Emergency and disaster preparedness assistance\n",
            "18 Shipwrecks\n",
            "19 Cybercrime, internet fraud, and cyber fraud\n",
            "22 Veteran's Benefits\n",
            "24 Air Bag Safety\n",
            "26 Nuclear power plants\n",
            "28 Early Childhood Education\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cvn5hVvw09D",
        "colab_type": "code",
        "outputId": "87869840-5eaf-4ba7-bb1b-ddff436620e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# print the first 10 lines in the qrels file\n",
        "with open(QRELS_FILE, \"r\") as f:\n",
        "    qrels10 = f.readlines()[:10]\n",
        "    print(\"\".join(qrels10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 0 G00-00-0681214 0\n",
            "1 0 G00-00-0945765 0\n",
            "1 0 G00-00-1006224 1\n",
            "1 0 G00-00-1591495 0\n",
            "1 0 G00-00-2764912 0\n",
            "1 0 G00-00-3253540 0\n",
            "1 0 G00-00-3717374 0\n",
            "1 0 G00-01-0270065 0\n",
            "1 0 G00-01-0400712 0\n",
            "1 0 G00-01-0682299 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoSOriNmw9AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pyTrecEval(topicFile, qrelsFile, queryParser, searcher):\n",
        "    # Load topic file - a list of topics(search phrases) used for evalutation\n",
        "    with open(topicFile, \"r\") as tf:\n",
        "        topics = tf.read().splitlines()\n",
        "\n",
        "    # create an output file to which we'll write our results\n",
        "    tempOutputFile = tempfile.mkstemp()[1]\n",
        "    with open(tempOutputFile, \"w\") as outputTRECFile:\n",
        "        # for each evaluated topic:\n",
        "        # build a query and record the results in the file in TREC_EVAL format\n",
        "        for topic in topics:\n",
        "            topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
        "            #print(topic_id, topic_phrase)\n",
        "            topicQuery = queryParser.parse(topic_phrase)\n",
        "            topicResults = searcher.search(topicQuery, limit=None)\n",
        "            for (docnum, result) in enumerate(topicResults):\n",
        "                score = topicResults.score(docnum)\n",
        "                #print(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "                outputTRECFile.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "    with open(qrelsFile, 'r') as f_qrel:\n",
        "        qrel = pytrec_eval.parse_qrel(f_qrel)\n",
        "\n",
        "    with open(tempOutputFile, 'r') as f_run:\n",
        "        run = pytrec_eval.parse_run(f_run)\n",
        "\n",
        "    evaluator = pytrec_eval.RelevanceEvaluator(\n",
        "        qrel, pytrec_eval.supported_measures)\n",
        "\n",
        "    results = evaluator.evaluate(run)\n",
        "    def print_line(measure, scope, value):\n",
        "        print('{:25s}{:8s}{:.4f}'.format(measure, scope, value))\n",
        "\n",
        "    for query_id, query_measures in results.items():\n",
        "        for measure, value in query_measures.items():\n",
        "            if measure == \"runid\":\n",
        "              continue\n",
        "            print_line(measure, query_id, value)\n",
        "    for measure in query_measures.keys():\n",
        "        if measure == \"runid\":\n",
        "              continue\n",
        "        print_line(\n",
        "            measure,\n",
        "            'all',\n",
        "            pytrec_eval.compute_aggregated_measure(\n",
        "                measure,\n",
        "                [query_measures[measure]\n",
        "                 for query_measures in results.values()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlV-V1XHxApw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Q2, SEARCHER_Q2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgFYPTecxPEH",
        "colab_type": "text"
      },
      "source": [
        "The chosen measure (MAP) is 0.1971"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TUIW6hV39Wz",
        "colab_type": "text"
      },
      "source": [
        "## Baseline Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tuWH6trc88x",
        "colab_type": "text"
      },
      "source": [
        "Topics that did well:\n",
        "- 18 Shipwrecks (MAP= 1)\n",
        "- 24 Air Bag Safety (MAP= 1)\n",
        "- 14 Agricultural biotechnology (MAP= 0.25)\n",
        "\n",
        "Topics that did badly:\n",
        "- 19 Cybercrime, internet fraud, and cyber fraud (did not even return a result)\n",
        "\n",
        "  Topics with 0 MAP:\n",
        "- 1 mining gold silver coal\n",
        "- 2 juvenile delinquency\n",
        "- 7 cotton industry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_e8DZ3K39W0",
        "colab_type": "text"
      },
      "source": [
        "## Improving on the baseline and investigation (why is the MAP score so low?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6CtdElz51Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printRelName(topicFile, qrelsFile, queryParser, searcher, id):\n",
        "  with open(topicFile, \"r\") as tf:\n",
        "        topics = tf.read().splitlines()\n",
        "  for topic in topics:\n",
        "        topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
        "        if topic_id == id:\n",
        "          print(\"---------------------------Topic_id and Topic_phrase----------------------------------\")\n",
        "          print(topic_id, topic_phrase)\n",
        "          topicQuery = queryParser.parse(topic_phrase)\n",
        "          topicResults = searcher.search(topicQuery, limit=None)\n",
        "          print(\"---------------------------Return documents----------------------------------\")\n",
        "          for (docnum, result) in enumerate(topicResults):\n",
        "              score = topicResults.score(docnum)\n",
        "              print(\"%s Q0 %s %d %lf test\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "          print(\"---------------------------Relevant documents----------------------------------\")\n",
        "          with open(qrelsFile, 'r') as f_qrel:\n",
        "            qrels = f_qrel.readlines()\n",
        "            for i in qrels:\n",
        "              qid, _, doc, rel = i.rstrip().split(\" \")\n",
        "              if qid == id and rel == \"1\":\n",
        "                print(i.rstrip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eFVQet552L3",
        "colab_type": "code",
        "outputId": "71924daa-56ff-4e7d-a57d-723737d470d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "printRelName(TOPIC_FILE, QRELS_FILE, QP_Q2, SEARCHER_Q2, \"19\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------Topic_id and Topic_phrase----------------------------------\n",
            "19 Cybercrime, internet fraud, and cyber fraud\n",
            "---------------------------Return documents----------------------------------\n",
            "---------------------------Relevant documents----------------------------------\n",
            "19 0 G00-02-3479535 1\n",
            "19 0 G00-10-2344253 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbv4iqI2hEIh",
        "colab_type": "text"
      },
      "source": [
        "The query chosen to investigate is 4- wireless communications since it had the lowest non-zero MAP score (0.0312)\n",
        "\n",
        "1) The documents that were highly ranked are:\n",
        "- G00-99-2247765 (Whoosh Score= 16.449155)\n",
        "- G00-85-1525415 (Whoosh Score= 13.364613)\n",
        "\n",
        "2) The documents that should have been highly ranked are:\n",
        "- G00-03-2855342 \n",
        "- G00-36-1275993 \n",
        "- G00-47-2117970 \n",
        "- G00-65-0162935 \n",
        "\n",
        "3) False positives (irrelevant documents highly ranked):\n",
        "- G00-99-2247765 (Whoosh Score= 16.449155)\n",
        "- G00-85-1525415 (Whoosh Score= 13.364613)\n",
        "\n",
        "False negatives (relevant documents not ranked highly):\n",
        "- G00-47-2117970 (Ranking= 7) (Whoosh Score= 10.213356)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGsO00XglJN9",
        "colab_type": "code",
        "outputId": "1cd52eb8-3339-4057-bc43-3fcbf06c4d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Quick check to see if index is empty or not\n",
        "# Is it empty?\n",
        "print(\"Index is empty?\", INDEX_Q2.is_empty())\n",
        "\n",
        "# How many files indexed?\n",
        "print(\"Number of indexed files:\", INDEX_Q2.doc_count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index is empty? False\n",
            "Number of indexed files: 4078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L2PTFpsNHZj",
        "colab_type": "text"
      },
      "source": [
        "The vaninlla whoosh system was run with just the Tokenizer which seperates the different words into token. However, there are various other form the words coud appear in.\n",
        "\n",
        "For example-\n",
        "- The term \"wireless communications\" could appear as capitalized letters and hence would not show as a match\n",
        "- \"communication\" could show up in the document and it would not show up as a match.\n",
        "\n",
        "Running a simple lowercase and stem filter should potentially improve the MAP score of this topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n5OmKZHUwWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a reader object on the index\n",
        "myReader = INDEX_Q2.reader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k8picLiVxZm",
        "colab_type": "text"
      },
      "source": [
        "Let's investigate the need for the two filters discussed above.\n",
        "The word communication could be present in so many different ways across the documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHhs07_bU03u",
        "colab_type": "code",
        "outputId": "adf0bdca-4e07-4c22-9e08-d231a4e6ec30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# the different variations of the same word\n",
        "print(\"# docs with 'communications'\", myReader.doc_frequency(\"file_content\", \"communications\"))\n",
        "print(\"# docs with 'communicate'\", myReader.doc_frequency(\"file_content\", \"communicate\"))\n",
        "print(\"# docs with 'communication'\", myReader.doc_frequency(\"file_content\", \"communication\"))\n",
        "print(\"# docs with 'Communication'\", myReader.doc_frequency(\"file_content\", \"Communication\"))\n",
        "\n",
        "print(\"\\n# docs with 'Wireless'\", myReader.doc_frequency(\"file_content\", \"Wireless\"))\n",
        "print(\"# docs with 'wireless'\", myReader.doc_frequency(\"file_content\", \"wireless\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# docs with 'communications' 102\n",
            "# docs with 'communicate' 45\n",
            "# docs with 'communication' 107\n",
            "# docs with 'Communication' 63\n",
            "\n",
            "# docs with 'Wireless' 51\n",
            "# docs with 'wireless' 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BASebspW8Lo",
        "colab_type": "text"
      },
      "source": [
        "As it can be seen, the two words appear in so many different forms. Applying the lower-case and stem filter (Snowball Stemmer) should drastically improve the performance of the IR system.\n",
        "As seen below, the filters would reduce various form of the words to the same root word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaHq4MnBVRJL",
        "colab_type": "code",
        "outputId": "be29e68c-10c1-4e36-c6bb-d2faec63a1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Checking how the analyzer would work for the different types \n",
        "stmLwrAnalyzer = RegexTokenizer() | LowercaseFilter() | StemFilter(lang= 'ru')\n",
        "print([token.text for token in stmLwrAnalyzer(\"communications\")])\n",
        "print([token.text for token in stmLwrAnalyzer(\"communicate\")])\n",
        "print([token.text for token in stmLwrAnalyzer(\"communication\")])\n",
        "print([token.text for token in stmLwrAnalyzer(\"Communication\")])\n",
        "\n",
        "print([token.text for token in stmLwrAnalyzer(\"wireless\")])\n",
        "print([token.text for token in stmLwrAnalyzer(\"Wireless\")])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['communications']\n",
            "['communicat']\n",
            "['communication']\n",
            "['communication']\n",
            "['wireless']\n",
            "['wireless']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYo6pmQzYuhS",
        "colab_type": "text"
      },
      "source": [
        "The words are now the same and would make it easier for the system to find the relevant documents. The same would hold true for the other topics as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAef6qiu39W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a Schema with the new analyzer\n",
        "\n",
        "stmLwrAnalyzer = RegexTokenizer() | LowercaseFilter() | StemFilter()\n",
        "mySchema2 = Schema(file_path = ID(stored=True),\n",
        "                   file_content = TEXT(analyzer = stmLwrAnalyzer))\n",
        "\n",
        "# create the index based on the new schema\n",
        "myIndex2 = createIndex(mySchema2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X4UJsehOh_v",
        "colab_type": "code",
        "outputId": "ceaf395f-0004-4cb2-b2b8-11f4496149ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "addFilesToIndex(myIndex2, filesToIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already indexed: 1000\n",
            "already indexed: 2000\n",
            "already indexed: 3000\n",
            "already indexed: 4000\n",
            "done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H6yUwtd39W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Q3 = myIndex2 # Replace None with your index for Q3\n",
        "QP_Q3 = QueryParser(\"file_content\", schema=INDEX_Q3.schema) # Replace None with your query parser for Q3\n",
        "SEARCHER_Q3 = INDEX_Q3.searcher() # Replace None with your searcher for Q3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQTPtZpOzqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Q3, SEARCHER_Q3) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skO_-ixLVq6i",
        "colab_type": "code",
        "outputId": "d335623c-43fd-4586-f101-36957b1cb81b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "printRelName(TOPIC_FILE, QRELS_FILE, QP_Q3, SEARCHER_Q3, \"19\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------Topic_id and Topic_phrase----------------------------------\n",
            "19 Cybercrime, internet fraud, and cyber fraud\n",
            "---------------------------Return documents----------------------------------\n",
            "19 Q0 G00-02-3479535 0 31.173572 test\n",
            "19 Q0 G00-27-1492903 1 28.493387 test\n",
            "19 Q0 G00-15-1460278 2 25.139250 test\n",
            "19 Q0 G00-73-0028862 3 19.084104 test\n",
            "19 Q0 G00-15-3429810 4 14.596646 test\n",
            "---------------------------Relevant documents----------------------------------\n",
            "19 0 G00-02-3479535 1\n",
            "19 0 G00-10-2344253 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QVFSnNuO_ZM",
        "colab_type": "text"
      },
      "source": [
        "There were two improvements made:\n",
        "- Lower Case: all the words in the documents and query were lower-cased\n",
        "- Stemming: This reduces all the words to its base word by removing the suffixes. There are other methods that could be used such as Lemmatization but for this step, Stemming was performed.\n",
        "\n",
        "The MAP for the topic 4 (wireless communications) increased from 0.0312 to 0.5375 (an increase of upto 16 times).\n",
        "Of the four relevant documents:\n",
        "- The first two ranked documents are relevant documents. \n",
        "- One of the relevant documents is ranked 19 (G00-65-0162935) \n",
        "- The last one is not in the returned documents list (G00-03-2855342).\n",
        "\n",
        "The False Negative document in the 3(b) is now ranked second and the false positive documents have moved down the rankings from the previous case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfY5XIuKiTry",
        "colab_type": "text"
      },
      "source": [
        "The overall MAP increased from 0.1971 to 0.3372."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsSZQvIHOCYi",
        "colab_type": "text"
      },
      "source": [
        "Queries that got better (as per MAP):\n",
        "- Topic 4 increased from 0.0312 to 0.5375\n",
        "- Topic 19 increased from no results to 0.5 \n",
        "- Topic 2 increased from 0 to 0.5\n",
        "\n",
        "\n",
        "Queries that got worse (as per MAP):\n",
        "- Topic 22 decreased from 0.2 to 0.056\n",
        "- Topic 26 decreased from 0.11 to 0.0778\n",
        "\n",
        "Most of the others remained the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs6teq2k39W-",
        "colab_type": "text"
      },
      "source": [
        "## Search Engine Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZROhOfIatWyJ",
        "colab_type": "text"
      },
      "source": [
        "The modifications are made in four main ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgOzt9Z9benA",
        "colab_type": "text"
      },
      "source": [
        "####Way 1- Adding filters and trying different analyzers:\n",
        "- Using the NLTK options to compare four different Text Analyzers: Snowball Stemmer, Lancaster Stemmer, Wordnet Lemmatizer, Wordnet Lemmatizer with verbs. \n",
        "\n",
        "Note that the IntraWord Filter was added to all beforehand. Intraword filter is used to break phrases like \"whooosh.analysis\" to \"whoosh\" and \"analysis\" to make it easier to match certain terms. Stop word filter is used to remove the words such as \"are\", \"and\", etc which do not add value to the search.\n",
        "\n",
        "Results:\n",
        "- Using the Lancaster Stemmer increased MAP from 0.3372 to 0.3457\n",
        "- Using Wordnet Lemmatizer increased MAP from 0.3372 to 0.3401\n",
        "- Using WordNet Lemmatizer for verbs increased MAP from 0.3372 to 0.3401\n",
        "- Using the Snowball Stemmer (same as Q3 but with additon of two new filters) reduced the MAP from 0.3372 to 0.3366.\n",
        "\n",
        "Lancaster Stemmer gave the best MAP score of 0.3457 and will be used further.\n",
        "\n",
        "The Lancaster Stemmer is just a different version as compared to the Snowball Stemmer but the idea is the same. It reduces the word to its root. Lemmatizers does the same function but it is slower and the result is an actual language word (unlike Stemmers). These analyzers in general aid in helping find the terms from the query in the documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNfdLdzfUUSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This filter will run for both the index and the query\n",
        "class CustomFilter(Filter):\n",
        "    is_morph = True\n",
        "    def __init__(self, filterFunc, *args, **kwargs):\n",
        "        self.customFilter = filterFunc\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "    def __eq__(self):\n",
        "        return (other\n",
        "                and self.__class__ is other.__class__)\n",
        "    def __call__(self, tokens):\n",
        "        for t in tokens:\n",
        "            if t.mode == 'query': # if called by query parser\n",
        "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
        "                yield t\n",
        "            else: # == 'index' if called by indexer\n",
        "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
        "                yield t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5OMjXr0UVfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myFilter1 = RegexTokenizer()| LowercaseFilter() | StopFilter()| IntraWordFilter()| CustomFilter(LancasterStemmer().stem)\n",
        "#myFilter2 = RegexTokenizer()| LowercaseFilter() | StopFilter()| IntraWordFilter()| CustomFilter(WordNetLemmatizer().lemmatize)\n",
        "#myFilter3 = RegexTokenizer()| LowercaseFilter() | StopFilter()| IntraWordFilter()| CustomFilter(WordNetLemmatizer().lemmatize, 'v')\n",
        "#myFilter4 = RegexTokenizer()| LowercaseFilter() | StopFilter()| IntraWordFilter()| StemFilter () \n",
        "\n",
        "# define a Schema with the new analyzer\n",
        "\n",
        "mySchema3 = Schema(file_path = ID(stored=True),\n",
        "                   file_content = TEXT(analyzer = myFilter1))\n",
        "\n",
        "# create the index based on the new schema\n",
        "myIndex3 = createIndex(mySchema3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bm5zsXfUayl",
        "colab_type": "code",
        "outputId": "241a8362-7973-4611-9627-27dc80503e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "addFilesToIndex(myIndex3, filesToIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already indexed: 1000\n",
            "already indexed: 2000\n",
            "already indexed: 3000\n",
            "already indexed: 4000\n",
            "done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1MLfC_39XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Way1 = myIndex3 \n",
        "QP_Way1 = QueryParser(\"file_content\", schema=INDEX_Way1.schema) \n",
        "SEARCHER_Way1 = INDEX_Way1.searcher() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QCD7Sq2U-ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Way1, SEARCHER_Way1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSSV1pa_bjTl",
        "colab_type": "text"
      },
      "source": [
        "#### Way 2- Using different types of scoring methods\n",
        "The two scoring methods used are: TF_IDF, BM25F and PL2\n",
        "(Reference: https://whoosh.readthedocs.io/en/latest/api/scoring.html, http://ir.dcs.gla.ac.uk/smooth/he-ecir05.pdf and https://en.wikipedia.org/wiki/Okapi_BM25)\n",
        "\n",
        "- TF_IDF also considers the rarity of the term in a document in addition to the frequency of the term. It gives a MAP of 0.1612\n",
        "- BM25F is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document, regardless of their proximity within the document. It is a family of scoring functions with slightly different components and parameters. It gives a MAP of 0.3547 (it is the default scorer)- but it has parameters that can be tuned.\n",
        "- PL2 is one of the divergence from randomness (DFR) document weighting models. It gave a MAP of 0.3245\n",
        "\n",
        "BM25F and PL2 both have parameters that can be tuned and hence they will both be used in Way 4.\n",
        "\n",
        "Scoring in general is important because the relevant documents need to come up in the higher ranks since user would not go through all the results to find the relevant one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTyZblfpbjl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Way2 = myIndex3 #Using the Index from Way 1\n",
        "QP_Way2 = QueryParser(\"file_content\", schema=INDEX_Way2.schema)\n",
        "\n",
        "#weighting= scoring.TF_IDF()\n",
        "#weighting= scoring.PL2()\n",
        "SEARCHER_Way2 = INDEX_Way2.searcher(weighting= scoring.BM25F())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svtrd-77huYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Way2, SEARCHER_Way2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GQO8oRHmjhy",
        "colab_type": "text"
      },
      "source": [
        "#### Way 3- Using AND/OR Filter\n",
        "\n",
        "There are different customizations which can be made to the query parser. (Reference: https://whoosh.readthedocs.io/en/latest/parsing.html)\n",
        "- AND Filter- meaning all the terms must be present for a document to match. This is the default setting which gives the MAP of 0.3446\n",
        "- OR Filter- any of the terms may be present for a document to match. For example, if the user searches for foo bar, a document with four occurances of foo would normally outscore a document that contained one occurance each of foo and bar. The MAP increases to 0.38.\n",
        "- the factory() class method of OrGroup: Users usually expect documents that contain more of the words they searched for to score higher. To configure the parser to produce Or groups with this behavior, the factory() class method of OrGroup is utilized. The MAP score is 0.3752.\n",
        "\n",
        "OR Filter is used further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ4wB9_unUh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Way3 = myIndex3 #Using the Index from Way 1\n",
        "#group= ANDGroup\n",
        "#group= OrGroup.factory(0.9)\n",
        "QP_Way3 = QueryParser(\"file_content\", schema=INDEX_Way3.schema, group= OrGroup) \n",
        "SEARCHER_Way3 = INDEX_Way3.searcher(weighting= scoring.BM25F())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqEKzOLLnixr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Way3, SEARCHER_Way3) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "021RLr78N95Y",
        "colab_type": "text"
      },
      "source": [
        "#### Way4- Parameter Tuning of BM25F and PL2\n",
        "Two main parameters of BM25- K1 and B (Reference: https://km.aifb.kit.edu/ws/semsearch10/Files/bm25f.pdf and http://www.minerazzi.com/tutorials/bm25f-model-tutorial.pdf)\n",
        "\n",
        "- k1 is a constant that allows us to control the non-linear growing term frequency function. This parameter controls how quickly an increase in term frequency results in term-frequency saturation.\n",
        "\n",
        "- B is a parameter for achieving full, soft, or zero document length normalization. \n",
        "\n",
        "Best MAP score- 0.4022 (B= 0.57, K1=6.0)\n",
        "\n",
        "Main parameter of PL2: \n",
        "- c is the free parameter of the normalisation method\n",
        "\n",
        "Best MAP score= 0.4098 (c=2.67)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLXGjLW-Wsat",
        "colab_type": "text"
      },
      "source": [
        "pyTrecEval function is modified to be able to loop through the different values of the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHEXi0oKORPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pyTrecEval_modified(topicFile, qrelsFile, queryParser, searcher):\n",
        "    # Load topic file - a list of topics(search phrases) used for evalutation\n",
        "    with open(topicFile, \"r\") as tf:\n",
        "        topics = tf.read().splitlines()\n",
        "\n",
        "    # create an output file to which we'll write our results\n",
        "    tempOutputFile = tempfile.mkstemp()[1]\n",
        "    with open(tempOutputFile, \"w\") as outputTRECFile:\n",
        "        # for each evaluated topic:\n",
        "        # build a query and record the results in the file in TREC_EVAL format\n",
        "        for topic in topics:\n",
        "            topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
        "            #print(topic_id, topic_phrase)\n",
        "            topicQuery = queryParser.parse(topic_phrase)\n",
        "            topicResults = searcher.search(topicQuery, limit=None)\n",
        "            for (docnum, result) in enumerate(topicResults):\n",
        "                score = topicResults.score(docnum)\n",
        "                #print(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "                outputTRECFile.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "    with open(qrelsFile, 'r') as f_qrel:\n",
        "        qrel = pytrec_eval.parse_qrel(f_qrel)\n",
        "\n",
        "    with open(tempOutputFile, 'r') as f_run:\n",
        "        run = pytrec_eval.parse_run(f_run)\n",
        "\n",
        "    evaluator = pytrec_eval.RelevanceEvaluator(\n",
        "        qrel, pytrec_eval.supported_measures)\n",
        "\n",
        "    results = evaluator.evaluate(run)\n",
        "    def print_line(measure, scope, value):\n",
        "      if measure == \"map\" and scope== \"all\":\n",
        "        global saved_value\n",
        "        saved_value= value\n",
        "        #print('{:25s}{:8s}{:.4f}'.format(measure, scope, value))\n",
        "\n",
        "    for query_id, query_measures in results.items():\n",
        "        for measure, value in query_measures.items():\n",
        "            if measure == \"runid\":\n",
        "              continue\n",
        "            print_line(measure, query_id, value)\n",
        "    for measure in query_measures.keys():\n",
        "        if measure == \"runid\":\n",
        "              continue\n",
        "        print_line(\n",
        "            measure,\n",
        "            'all',\n",
        "            pytrec_eval.compute_aggregated_measure(\n",
        "                measure,\n",
        "                [query_measures[measure]\n",
        "                 for query_measures in results.values()]))\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVRne9RzX7ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Way4 = myIndex3 #Using the Index from Way 1\n",
        "QP_Way4 = QueryParser(\"file_content\", schema=INDEX_Way4.schema, group= OrGroup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_LABDfFXNkA",
        "colab_type": "text"
      },
      "source": [
        "The next two code blocks were used various times to obtain the best value of the parameters B and K1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBvBEA5vXmg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAP_K1= []\n",
        "K1= []\n",
        "for i in np.arange(0,7, 0.1):\n",
        "  SEARCHER_Way4 = INDEX_Way4.searcher(weighting= scoring.BM25F(B= 0.57, K1=i))\n",
        "  pyTrecEval_modified(TOPIC_FILE, QRELS_FILE, QP_Way4, SEARCHER_Way4)\n",
        "  MAP_K1.append(saved_value)\n",
        "  K1.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-7a7-5SYT1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Effect of changing K1 parameter on MAP value with a constant B parameter\n",
        "plt.plot(K1, MAP_K1)\n",
        "plt.title(\"Overall MAP vs K1\")\n",
        "plt.xlabel('K1')\n",
        "plt.ylabel(\"Overall MAP\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNEdAznV3gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAP_B= []\n",
        "B= []\n",
        "for i in np.arange(0, 1, 0.01):\n",
        "  SEARCHER_Way4 = INDEX_Way4.searcher(weighting=scoring.BM25F(B= i, K1=6))\n",
        "  pyTrecEval_modified(TOPIC_FILE, QRELS_FILE, QP_Way4, SEARCHER_Way4)\n",
        "  MAP_B.append(saved_value)\n",
        "  B.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyEm9oj0am6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Effect of changing B parameter on MAP value with a constant K1 parameter\n",
        "plt.plot(B, MAP_B)\n",
        "plt.title(\"Overall MAP vs B\")\n",
        "plt.xlabel('B')\n",
        "plt.ylabel(\"Overall MAP\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0NZwhz-a96U",
        "colab_type": "text"
      },
      "source": [
        "Using the above tuning method, the best parameters were obtained (B= 0.57, K1=6)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkGcmPU8b0dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using the best parameters from the above tuning\n",
        "SEARCHER_Way4 = INDEX_Way4.searcher(weighting=scoring.BM25F(B= 0.57, K1=6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEHSzRs1cXqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Way4, SEARCHER_Way4) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxIS4-q1GUOi",
        "colab_type": "text"
      },
      "source": [
        "Now to tune the c parameter in PL2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COikEXLOGXAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAP_c= []\n",
        "c= []\n",
        "for i in np.arange(0.1, 3, 0.1):\n",
        "  SEARCHER_Way4 = INDEX_Way4.searcher(weighting=scoring.PL2())\n",
        "  pyTrecEval_modified(TOPIC_FILE, QRELS_FILE, QP_Way4, SEARCHER_Way4)\n",
        "  MAP_c.append(saved_value)\n",
        "  c.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN5DYAgWGsYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Effect of changing c parameter on MAP value\n",
        "plt.plot(c, MAP_c)\n",
        "plt.title(\"Overall MAP vs c (PL2)\")\n",
        "plt.xlabel('c')\n",
        "plt.ylabel(\"Overall MAP\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h8TVKjmHgr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using the best parameters from the above tuning\n",
        "SEARCHER_Way4 = INDEX_Way4.searcher(weighting=scoring.PL2(c=2.67))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKXLzsmcHg_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Way4, SEARCHER_Way4) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxlhZbQRrNgR",
        "colab_type": "text"
      },
      "source": [
        "#### Other modifications tried:\n",
        "- Bi-word filter\n",
        "- Charset Filter\n",
        "- Different tokenizers\n",
        "- Different scoring methods such as Frequency and Function Weighting\n",
        "\n",
        "They all resulted in worse MAP scores and hence are not included within this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16vuqPCokzmT",
        "colab_type": "text"
      },
      "source": [
        "### Final Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlpZZH5-k1_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Q4 = myIndex3 # Replace None with your index for Q4\n",
        "QP_Q4 = QueryParser(\"file_content\", schema=INDEX_Q4.schema, group= OrGroup) # Replace None with your query parser for Q4\n",
        "SEARCHER_Q4 = INDEX_Q4.searcher(weighting=scoring.PL2(c=2.67)) # Replace None with your searcher for Q4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PnOeQM1lyio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, QP_Q4, SEARCHER_Q4) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmELrRhPsaal",
        "colab_type": "text"
      },
      "source": [
        "Final MAP= 0.41\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGcGddmR39Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}